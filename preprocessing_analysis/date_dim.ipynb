{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>order_status</th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "      <th>order_approved_at</th>\n",
       "      <th>order_delivered_carrier_date</th>\n",
       "      <th>order_delivered_customer_date</th>\n",
       "      <th>order_estimated_delivery_date</th>\n",
       "      <th>days_to_delivery</th>\n",
       "      <th>estimated_days_to_delivery</th>\n",
       "      <th>delay_flag_estimated</th>\n",
       "      <th>delay_flag_maen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e481f51cbdc54678b7cc49136f2d6af7</td>\n",
       "      <td>9ef432eb6251297304e76186b10a928d</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-10-02 10:56:33</td>\n",
       "      <td>2017-10-02 11:07:15</td>\n",
       "      <td>2017-10-04 19:55:00</td>\n",
       "      <td>2017-10-10 21:25:13</td>\n",
       "      <td>2017-10-18</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53cdb2fc8bc7dce0b6741e2150273451</td>\n",
       "      <td>b0830fb4747a6c6d20dea0b8c802d7ef</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-07-24 20:41:37</td>\n",
       "      <td>2018-07-26 03:24:27</td>\n",
       "      <td>2018-07-26 14:31:00</td>\n",
       "      <td>2018-08-07 15:27:45</td>\n",
       "      <td>2018-08-13</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47770eb9100c2d0c44946d9cf07ec65d</td>\n",
       "      <td>41ce2a54c0b03bf3443c3d931a367089</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-08-08 08:38:49</td>\n",
       "      <td>2018-08-08 08:55:23</td>\n",
       "      <td>2018-08-08 13:50:00</td>\n",
       "      <td>2018-08-17 18:06:29</td>\n",
       "      <td>2018-09-04</td>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>949d5b44dbf5de918fe9c16f97b45f8a</td>\n",
       "      <td>f88197465ea7920adcdbec7375364d82</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-11-18 19:28:06</td>\n",
       "      <td>2017-11-18 19:45:59</td>\n",
       "      <td>2017-11-22 13:39:59</td>\n",
       "      <td>2017-12-02 00:28:42</td>\n",
       "      <td>2017-12-15</td>\n",
       "      <td>13</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ad21c59c0840e6cb83a9ceb5573f8159</td>\n",
       "      <td>8ab97904e6daea8866dbdbc4fb7aad2c</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-02-13 21:18:39</td>\n",
       "      <td>2018-02-13 22:20:29</td>\n",
       "      <td>2018-02-14 19:46:34</td>\n",
       "      <td>2018-02-16 18:17:02</td>\n",
       "      <td>2018-02-26</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           order_id                       customer_id  \\\n",
       "0  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
       "1  53cdb2fc8bc7dce0b6741e2150273451  b0830fb4747a6c6d20dea0b8c802d7ef   \n",
       "2  47770eb9100c2d0c44946d9cf07ec65d  41ce2a54c0b03bf3443c3d931a367089   \n",
       "3  949d5b44dbf5de918fe9c16f97b45f8a  f88197465ea7920adcdbec7375364d82   \n",
       "4  ad21c59c0840e6cb83a9ceb5573f8159  8ab97904e6daea8866dbdbc4fb7aad2c   \n",
       "\n",
       "  order_status order_purchase_timestamp    order_approved_at  \\\n",
       "0    delivered      2017-10-02 10:56:33  2017-10-02 11:07:15   \n",
       "1    delivered      2018-07-24 20:41:37  2018-07-26 03:24:27   \n",
       "2    delivered      2018-08-08 08:38:49  2018-08-08 08:55:23   \n",
       "3    delivered      2017-11-18 19:28:06  2017-11-18 19:45:59   \n",
       "4    delivered      2018-02-13 21:18:39  2018-02-13 22:20:29   \n",
       "\n",
       "  order_delivered_carrier_date order_delivered_customer_date  \\\n",
       "0          2017-10-04 19:55:00           2017-10-10 21:25:13   \n",
       "1          2018-07-26 14:31:00           2018-08-07 15:27:45   \n",
       "2          2018-08-08 13:50:00           2018-08-17 18:06:29   \n",
       "3          2017-11-22 13:39:59           2017-12-02 00:28:42   \n",
       "4          2018-02-14 19:46:34           2018-02-16 18:17:02   \n",
       "\n",
       "  order_estimated_delivery_date  days_to_delivery  estimated_days_to_delivery  \\\n",
       "0                    2017-10-18                 8                          15   \n",
       "1                    2018-08-13                12                          17   \n",
       "2                    2018-09-04                 9                          26   \n",
       "3                    2017-12-15                13                          26   \n",
       "4                    2018-02-26                 2                          12   \n",
       "\n",
       "   delay_flag_estimated  delay_flag_maen  \n",
       "0                     0                0  \n",
       "1                     0                1  \n",
       "2                     0                0  \n",
       "3                     0                1  \n",
       "4                     0                0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('fact_orders.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dim_date 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/01 09:42:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "# Spark 세션 생성\n",
    "spark = SparkSession.builder.appName(\"olist\").getOrCreate()\n",
    "\n",
    "spk_orders = spark.read.csv('fact_orders.csv', header=True, inferSchema=True)\n",
    "spk_orders.createOrReplaceTempView(\"orders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/01 06:29:17 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>2018-12-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>2018-12-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>2018-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>2018-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>2019-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1097 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      full_date\n",
       "0    2016-01-01\n",
       "1    2016-01-02\n",
       "2    2016-01-03\n",
       "3    2016-01-04\n",
       "4    2016-01-05\n",
       "...         ...\n",
       "1092 2018-12-28\n",
       "1093 2018-12-29\n",
       "1094 2018-12-30\n",
       "1095 2018-12-31\n",
       "1096 2019-01-01\n",
       "\n",
       "[1097 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, expr, to_date, date_format\n",
    "import pandas as pd\n",
    "\n",
    "# Spark 세션 생성\n",
    "spark = SparkSession.builder.appName(\"CreateDimDate\").getOrCreate()\n",
    "\n",
    "# ✅ 1. 날짜 범위 생성 (2016년 1월 1일 ~ 2019년 1월 1일)\n",
    "date_range = pd.date_range(start=\"2016-01-01\", end=\"2019-01-01\", freq='D')\n",
    "date_df = pd.DataFrame({'full_date': date_range})  # Pandas DataFrame 생성\n",
    "date_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- withColumn 함수를 사용하여 매핑된 칼럼을 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+-----+---+----+-------+-----------+----------+\n",
      "| full_date|year|month|day|week|quarter|day_of_week|is_weekend|\n",
      "+----------+----+-----+---+----+-------+-----------+----------+\n",
      "|2015-12-31|2015|   12| 31|  53|      4|   Thursday|         0|\n",
      "|2016-01-01|2016|    1|  1|  53|      1|     Friday|         0|\n",
      "|2016-01-02|2016|    1|  2|  53|      1|   Saturday|         1|\n",
      "|2016-01-03|2016|    1|  3|  53|      1|     Sunday|         1|\n",
      "|2016-01-04|2016|    1|  4|   1|      1|     Monday|         0|\n",
      "|2016-01-05|2016|    1|  5|   1|      1|    Tuesday|         0|\n",
      "|2016-01-06|2016|    1|  6|   1|      1|  Wednesday|         0|\n",
      "|2016-01-07|2016|    1|  7|   1|      1|   Thursday|         0|\n",
      "|2016-01-08|2016|    1|  8|   1|      1|     Friday|         0|\n",
      "|2016-01-09|2016|    1|  9|   1|      1|   Saturday|         1|\n",
      "+----------+----+-----+---+----+-------+-----------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, to_date, expr, date_format, from_utc_timestamp\n",
    "\n",
    "\n",
    "dim_date = spark.createDataFrame(date_df)\n",
    "\n",
    "# 날짜 변환: 브라질 시간대 설정 (UTC → UTC-3 변환)\n",
    "dim_date = dim_date.withColumn(\"full_date\", to_date(from_utc_timestamp(col(\"full_date\"), \"America/Sao_Paulo\")))\n",
    "\n",
    "\n",
    "dim_date = dim_date.withColumn(\"year\", expr(\"YEAR(full_date)\"))\n",
    "dim_date = dim_date.withColumn(\"month\", expr(\"MONTH(full_date)\"))\n",
    "dim_date = dim_date.withColumn(\"day\", expr(\"DAY(full_date)\"))\n",
    "dim_date = dim_date.withColumn(\"week\", expr(\"WEEKOFYEAR(full_date)\"))\n",
    "dim_date = dim_date.withColumn(\"quarter\", expr(\"QUARTER(full_date)\"))\n",
    "\n",
    "\n",
    "dim_date = dim_date.withColumn(\"day_of_week\", date_format(col(\"full_date\"), \"EEEE\"))  # 'Monday', 'Tuesday', ...\n",
    "dim_date = dim_date.withColumn(\"is_weekend\", expr(\"CASE WHEN day_of_week IN ('Saturday', 'Sunday') THEN 1 ELSE 0 END\"))\n",
    "\n",
    "dim_date.show(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dim_date.toPandas().to_csv('dim_date.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_date = spark.read.csv('dim_date.csv', header=True, inferSchema=True)\n",
    "dim_date.createOrReplaceTempView(\"dim_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+------------------------+-------------------+----------------------------+-----------------------------+-----------------------------+----------------+--------------------------+--------------------+---------------+----------+----+-----+---+----+-------+-----------+----------+\n",
      "|            order_id|         customer_id|order_status|order_purchase_timestamp|  order_approved_at|order_delivered_carrier_date|order_delivered_customer_date|order_estimated_delivery_date|days_to_delivery|estimated_days_to_delivery|delay_flag_estimated|delay_flag_maen| full_date|year|month|day|week|quarter|day_of_week|is_weekend|\n",
      "+--------------------+--------------------+------------+------------------------+-------------------+----------------------------+-----------------------------+-----------------------------+----------------+--------------------------+--------------------+---------------+----------+----+-----+---+----+-------+-----------+----------+\n",
      "|e481f51cbdc54678b...|9ef432eb625129730...|   delivered|     2017-10-02 10:56:33|2017-10-02 11:07:15|         2017-10-04 19:55:00|          2017-10-10 21:25:13|                   2017-10-18|               8|                        15|                   0|              0|2017-10-02|2017|   10|  2|  40|      4|     Monday|         0|\n",
      "|53cdb2fc8bc7dce0b...|b0830fb4747a6c6d2...|   delivered|     2018-07-24 20:41:37|2018-07-26 03:24:27|         2018-07-26 14:31:00|          2018-08-07 15:27:45|                   2018-08-13|              12|                        17|                   0|              1|2018-07-24|2018|    7| 24|  30|      3|    Tuesday|         0|\n",
      "|47770eb9100c2d0c4...|41ce2a54c0b03bf34...|   delivered|     2018-08-08 08:38:49|2018-08-08 08:55:23|         2018-08-08 13:50:00|          2018-08-17 18:06:29|                   2018-09-04|               9|                        26|                   0|              0|2018-08-08|2018|    8|  8|  32|      3|  Wednesday|         0|\n",
      "|949d5b44dbf5de918...|f88197465ea7920ad...|   delivered|     2017-11-18 19:28:06|2017-11-18 19:45:59|         2017-11-22 13:39:59|          2017-12-02 00:28:42|                   2017-12-15|              13|                        26|                   0|              1|2017-11-18|2017|   11| 18|  46|      4|   Saturday|         1|\n",
      "|ad21c59c0840e6cb8...|8ab97904e6daea886...|   delivered|     2018-02-13 21:18:39|2018-02-13 22:20:29|         2018-02-14 19:46:34|          2018-02-16 18:17:02|                   2018-02-26|               2|                        12|                   0|              0|2018-02-13|2018|    2| 13|   7|      1|    Tuesday|         0|\n",
      "|a4591c265e18cb1dc...|503740e9ca751ccdd...|   delivered|     2017-07-09 21:57:05|2017-07-09 22:10:13|         2017-07-11 14:58:04|          2017-07-26 10:57:55|                   2017-08-01|              16|                        22|                   0|              1|2017-07-09|2017|    7|  9|  27|      3|     Sunday|         1|\n",
      "|6514b8ad8028c9f2c...|9bdf08b4b3b52b552...|   delivered|     2017-05-16 13:10:30|2017-05-16 13:22:11|         2017-05-22 10:07:46|          2017-05-26 12:55:51|                   2017-06-07|               9|                        21|                   0|              0|2017-05-16|2017|    5| 16|  20|      2|    Tuesday|         0|\n",
      "|76c6e866289321a7c...|f54a9f0e6b351c431...|   delivered|     2017-01-23 18:29:09|2017-01-25 02:50:47|         2017-01-26 14:16:31|          2017-02-02 14:08:10|                   2017-03-06|               8|                        39|                   0|              0|2017-01-23|2017|    1| 23|   4|      1|     Monday|         0|\n",
      "|e69bfb5eb88e0ed6a...|31ad1d1b63eb99624...|   delivered|     2017-07-29 11:55:02|2017-07-29 12:05:32|         2017-08-10 19:45:24|          2017-08-16 17:14:30|                   2017-08-23|              18|                        24|                   0|              1|2017-07-29|2017|    7| 29|  30|      3|   Saturday|         1|\n",
      "|e6ce16cb79ec1d90b...|494dded5b201313c6...|   delivered|     2017-05-16 19:41:10|2017-05-16 19:50:18|         2017-05-18 11:40:40|          2017-05-29 11:18:31|                   2017-06-07|              12|                        21|                   0|              1|2017-05-16|2017|    5| 16|  20|      2|    Tuesday|         0|\n",
      "+--------------------+--------------------+------------+------------------------+-------------------+----------------------------+-----------------------------+-----------------------------+----------------+--------------------------+--------------------+---------------+----------+----+-----+---+----+-------+-----------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fact_orders_date = spk_orders.join(dim_date,on=spk_orders.order_purchase_timestamp.cast(\"date\") == dim_date.full_date,how='left')\n",
    "fact_orders_date.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_orders_date.createOrReplaceTempView(\"fact_orders_date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 월 별 days_to_delivery 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|avg_days_to_delivery|month|\n",
      "+--------------------+-----+\n",
      "|  11.071378091872791|    1|\n",
      "|  12.389874810840556|    2|\n",
      "|  11.517286135693215|    3|\n",
      "|    9.94654015274242|    4|\n",
      "|   9.619757118073272|    5|\n",
      "|   8.587733272644515|    6|\n",
      "|   8.452512254901961|    7|\n",
      "|   7.928440543929019|    8|\n",
      "|  10.154037886340976|    9|\n",
      "|  10.154861111111112|   10|\n",
      "+--------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT AVG(days_to_delivery) AS avg_days_to_delivery,\n",
    "        month\n",
    "  FROM fact_orders_date\n",
    " GROUP BY  month\n",
    " ORDER BY  month\n",
    "\"\"\"\n",
    "spark.sql(query).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|avg_days_to_delivery|month|\n",
      "+--------------------+-----+\n",
      "|  11.071378091872791|    1|\n",
      "|  12.389874810840556|    2|\n",
      "|  11.517286135693215|    3|\n",
      "|    9.94654015274242|    4|\n",
      "|   9.619757118073272|    5|\n",
      "|   8.587733272644515|    6|\n",
      "|   8.452512254901961|    7|\n",
      "|   7.928440543929019|    8|\n",
      "|  10.154037886340976|    9|\n",
      "|  10.154861111111112|   10|\n",
      "+--------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT AVG(days_to_delivery) AS avg_days_to_delivery,\n",
    "        MONTH(order_purchase_timestamp) AS month\n",
    "  FROM fact_orders_date\n",
    " GROUP BY  MONTH(order_purchase_timestamp) \n",
    " ORDER BY  MONTH(order_purchase_timestamp)\n",
    "\n",
    "\"\"\"\n",
    "spark.sql(query).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
